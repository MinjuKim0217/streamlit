{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA/3igqPXAfE4o3snHFpOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinjuKim0217/streamlit/blob/main/%EB%9E%AD%EC%B2%B4%EC%9D%B8_%EC%9D%B4%EB%A0%A5%EC%84%9C%EC%9E%91%EC%84%B1_%EC%98%88%EC%8B%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 필요 라이브러리 임포트"
      ],
      "metadata": {
        "id": "vO2ABz2LORaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRgPb9umIV6x",
        "outputId": "e4491508-21f6-45fb-dbea-74357d3a7d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m879.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.0\n",
            "Collecting bt\n",
            "  Downloading bt-0.2.9.tar.gz (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ffn>=0.3.5 (from bt)\n",
            "  Downloading ffn-0.3.7-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pyprind>=2.11 (from bt)\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: decorator>=4 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (4.4.2)\n",
            "Requirement already satisfied: matplotlib>=1 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.5 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (1.5.3)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (0.10.0)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.15 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (1.11.2)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (0.9.0)\n",
            "Requirement already satisfied: yfinance>=0.2 in /usr/local/lib/python3.10/dist-packages (from ffn>=0.3.5->bt) (0.2.28)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1->ffn>=0.3.5->bt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.19->ffn>=0.3.5->bt) (2023.3.post1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->ffn>=0.3.5->bt) (4.9.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->ffn>=0.3.5->bt) (2.31.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.15->ffn>=0.3.5->bt) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.15->ffn>=0.3.5->bt) (3.2.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance>=0.2->ffn>=0.3.5->bt) (0.0.11)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance>=0.2->ffn>=0.3.5->bt) (1.4.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance>=0.2->ffn>=0.3.5->bt) (2.3.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance>=0.2->ffn>=0.3.5->bt) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance>=0.2->ffn>=0.3.5->bt) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance>=0.2->ffn>=0.3.5->bt) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance>=0.2->ffn>=0.3.5->bt) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance>=0.2->ffn>=0.3.5->bt) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=0.3.5->bt) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=0.3.5->bt) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=0.3.5->bt) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->ffn>=0.3.5->bt) (2023.7.22)\n",
            "Building wheels for collected packages: bt\n",
            "  Building wheel for bt (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bt: filename=bt-0.2.9-cp310-cp310-linux_x86_64.whl size=1013362 sha256=d2dcaa08c11b4a126f2b8da4c294b970155537b4e38b243554d59e53236251b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5e/95/48051c377a1860daa09cd2e352e270ee21ae13cd1b6a95f722\n",
            "Successfully built bt\n",
            "Installing collected packages: pyprind, ffn, bt\n",
            "Successfully installed bt-0.2.9 ffn-0.3.7 pyprind-2.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pymysql\n",
        "!pip install bt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install PromptTemplate\n",
        "!pip install load_summarize_chain\n",
        "!pip install Document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y44cOR6IIWqn",
        "outputId": "00f4b604-cf48-4cb1-d1cf-fec407b7894d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.286-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
            "  Downloading langsmith-0.0.35-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.286 langsmith-0.0.35 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement PromptTemplate (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for PromptTemplate\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement load_summarize_chain (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for load_summarize_chain\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting Document\n",
            "  Downloading document-1.0.zip (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Document\n",
            "  Building wheel for Document (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Document: filename=document-1.0-py3-none-any.whl size=8764 sha256=ca033cc6f950fd341d4b8fc2b670f826677a675f281c6e4896a8bcb1d374d78f\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/ac/8e/4bf7a4f454fcbd96af3be9f23268ee72151302643d5b8d5290\n",
            "Successfully built Document\n",
            "Installing collected packages: Document\n",
            "Successfully installed Document-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtDyi5d_IY5M",
        "outputId": "cbab5b94-8a88-46a5-eb66-e13f8e0d32f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 랭체인 불러오기"
      ],
      "metadata": {
        "id": "fYgtGQQoOXBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "def GPT_with_docs(prompt_template, docs):\n",
        "    llm = ChatOpenAI(openai_api_key=\"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\",\n",
        "                     model_name=\"gpt-3.5-turbo\",\n",
        "                     temperature=0)\n",
        "\n",
        "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "    chain = load_summarize_chain(llm,\n",
        "                             chain_type=\"map_reduce\",\n",
        "                             return_intermediate_steps=True,\n",
        "                             map_prompt=PROMPT,\n",
        "                             combine_prompt=PROMPT)"
      ],
      "metadata": {
        "id": "Q2crRRSKIdhd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 걍 박아놓음\n",
        "구조화 1도 안된 걍 생 데이터 넣어봤음"
      ],
      "metadata": {
        "id": "niUr6qHjOZ1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stock_names = \"노타\"\n",
        "\n",
        "context = f\"\"\"\n",
        "    Follows are the top news titles related with {stock_names}, which are the best stocks in the second quarter of FY23.\n",
        "\n",
        "    AI 보편화를 추구하는 기업, 노타입니다.\n",
        "노타는 다양한 산업과 애플리케이션 전반에 걸쳐 AI 사용을 보편화하여 모든 사람에게 어디에서나 AI를 활용할 수 있는 것을 목표로 합니다.\n",
        "노타의 핵심 제품은 인공지능 원천기술인 딥러닝 모델 경량화 기술을 기반으로 AI 모델 개발 프로세스를 자동화 하는 AI 최적화 플랫폼, **넷츠프레소(NetsPresso)**입니다. 더불어 노타의 AI 최적화 기술은 지능형 교통 시스템 및 저전력 운전자 모니터링 시스템을 포함한 다양한 AI 솔루션 또한 제안합니다.\n",
        "국내 스타트업으로는 최초로 삼성과 LG의 투자 유치 기록을 보유하고 있으며, 네이버 D2SF가 최초로 투자한 스타트업입니다. 노타는 세계 시장을 선도하는 NVIDIA, Intel, ARM 등과 같은 기업들과 강력한 파트너십을 구축하여 해외 AI 시장 진출에 박차를 가하고 있습니다.\n",
        "노타크루가 업무에 몰두할 수 있는 최적의 환경을 만들고자 합니다. 자율성에서 나오는 시너지와 효율을 위해 재택근무와 자율출퇴근제를 시행 중입니다. 또한 열일하는 노타크루를 위한 아낌 없는 지원도 준비되어 있으니, 노타와 함께 성장할 기회를 놓치지 마세요!\n",
        "\n",
        "\t•\t재택근무제\n",
        "\t•\t자율출퇴근제\n",
        "\t•\t간식 & 야근 식사\n",
        "\t•\t야간 택시비\n",
        "\t•\t팀 회식비 & 티타임\n",
        "\t•\t모션 데스크\n",
        "\t•\t업무에 최적화된 사무 공간\n",
        "\n",
        "노타크루가 오너십을 가진다면 회사의 발전이 본인의 발전이라고 느낄 수 있고, 성장에 더욱 보람을 느낄 수 있어요. 우리 회사는 노타크루가 노타를 내 회사라고 느끼고 더 아끼길 바라기 때문에 그만큼 회사가 먼저 노력해야 한다고 믿어요.\n",
        "\n",
        "Customer-Centric\n",
        "\n",
        "우리는 AI 보편화를 위해 더 많은 사람이 우리의 기술력을 느낄 수 있도록 고객 중심적인 결정을 내려야 해요.\n",
        "우리의 고객이 누구인지 인지하고 의사결정을 했는지, 고객이 가장 원하는 부분을 최대한 충족시키고자 했는지, 고객 중심적인 관점에서 바라보고 업무를 진행해요.\n",
        "Think Big\n",
        "\n",
        "세상을 혁신하고자 하는 우리는 보다 대담한 목표를 제시할 필요가 있어요. 그런 우리가 눈앞에 있는 일에만 매몰되어 있을 틈은 없겠죠. 더욱 높이, 더욱 멀리 내다보며 장기적인 성공을 향해 나아가는 것이 Think Big 하는 우리의 자세입니다.\n",
        "Be Proactive\n",
        "\n",
        "누군가가 나서기 전에 내가 앞서서, 누군가가 시키기 전에 내가 먼저 행동하는 것이 Proactive한 사람의 기본자세입니다. 작은 움직임이라고 생각이 들어도 내가 주도적으로 행동한다면, 그 움직임이 차곡차곡 쌓여 큰 변화를 이루어낼 수 있어요.\n",
        "이것은 곧 프로(Pro)다운 행동(Active)이기도 하지요!\n",
        "Disagree & Commit\n",
        "\n",
        "생산적인 논쟁을 위해서 우리는 더욱 적극적으로 파악하고 비판해야 해요. 다름을 인정하고 건설적인 피드백을 나누는 과정에서 더 나은 방향을 찾게 될 수 있고 어쩌면 생각지도 못한 새로운 결과가 도출될 수도 있어요. 또한, 같은 목표를 가지고 결정된 내용이기 때문에 결론에 대한 믿음도 수용의 일부라고 생각해야해요.\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(context)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg-DrYmEIgNp",
        "outputId": "5aa1b936-fc96-4ad5-cb54-223b08b8ce90"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Follows are the top news titles related with 노타, which are the best stocks in the second quarter of FY23.\n",
            "\n",
            "    AI 보편화를 추구하는 기업, 노타입니다.\n",
            "노타는 다양한 산업과 애플리케이션 전반에 걸쳐 AI 사용을 보편화하여 모든 사람에게 어디에서나 AI를 활용할 수 있는 것을 목표로 합니다.\n",
            "노타의 핵심 제품은 인공지능 원천기술인 딥러닝 모델 경량화 기술을 기반으로 AI 모델 개발 프로세스를 자동화 하는 AI 최적화 플랫폼, **넷츠프레소(NetsPresso)**입니다. 더불어 노타의 AI 최적화 기술은 지능형 교통 시스템 및 저전력 운전자 모니터링 시스템을 포함한 다양한 AI 솔루션 또한 제안합니다.\n",
            "국내 스타트업으로는 최초로 삼성과 LG의 투자 유치 기록을 보유하고 있으며, 네이버 D2SF가 최초로 투자한 스타트업입니다. 노타는 세계 시장을 선도하는 NVIDIA, Intel, ARM 등과 같은 기업들과 강력한 파트너십을 구축하여 해외 AI 시장 진출에 박차를 가하고 있습니다.\n",
            "노타크루가 업무에 몰두할 수 있는 최적의 환경을 만들고자 합니다. 자율성에서 나오는 시너지와 효율을 위해 재택근무와 자율출퇴근제를 시행 중입니다. 또한 열일하는 노타크루를 위한 아낌 없는 지원도 준비되어 있으니, 노타와 함께 성장할 기회를 놓치지 마세요!\n",
            "\n",
            "\t•\t재택근무제\n",
            "\t•\t자율출퇴근제\n",
            "\t•\t간식 & 야근 식사\n",
            "\t•\t야간 택시비\n",
            "\t•\t팀 회식비 & 티타임\n",
            "\t•\t모션 데스크\n",
            "\t•\t업무에 최적화된 사무 공간\n",
            "\n",
            "노타크루가 오너십을 가진다면 회사의 발전이 본인의 발전이라고 느낄 수 있고, 성장에 더욱 보람을 느낄 수 있어요. 우리 회사는 노타크루가 노타를 내 회사라고 느끼고 더 아끼길 바라기 때문에 그만큼 회사가 먼저 노력해야 한다고 믿어요.\n",
            "\n",
            "Customer-Centric\n",
            "\n",
            "우리는 AI 보편화를 위해 더 많은 사람이 우리의 기술력을 느낄 수 있도록 고객 중심적인 결정을 내려야 해요.\n",
            "우리의 고객이 누구인지 인지하고 의사결정을 했는지, 고객이 가장 원하는 부분을 최대한 충족시키고자 했는지, 고객 중심적인 관점에서 바라보고 업무를 진행해요.\n",
            "Think Big\n",
            "\n",
            "세상을 혁신하고자 하는 우리는 보다 대담한 목표를 제시할 필요가 있어요. 그런 우리가 눈앞에 있는 일에만 매몰되어 있을 틈은 없겠죠. 더욱 높이, 더욱 멀리 내다보며 장기적인 성공을 향해 나아가는 것이 Think Big 하는 우리의 자세입니다.\n",
            "Be Proactive\n",
            "\n",
            "누군가가 나서기 전에 내가 앞서서, 누군가가 시키기 전에 내가 먼저 행동하는 것이 Proactive한 사람의 기본자세입니다. 작은 움직임이라고 생각이 들어도 내가 주도적으로 행동한다면, 그 움직임이 차곡차곡 쌓여 큰 변화를 이루어낼 수 있어요.\n",
            "이것은 곧 프로(Pro)다운 행동(Active)이기도 하지요!\n",
            "Disagree & Commit\n",
            "\n",
            "생산적인 논쟁을 위해서 우리는 더욱 적극적으로 파악하고 비판해야 해요. 다름을 인정하고 건설적인 피드백을 나누는 과정에서 더 나은 방향을 찾게 될 수 있고 어쩌면 생각지도 못한 새로운 결과가 도출될 수도 있어요. 또한, 같은 목표를 가지고 결정된 내용이기 때문에 결론에 대한 믿음도 수용의 일부라고 생각해야해요.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 `question` 에서 프롬프트 엔지니어링"
      ],
      "metadata": {
        "id": "oWEbpJBaOiCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "OPENAI_API_KEY = \"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\"\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end in Korean.\n",
        "\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Please write me a resume for the company that i gave the information about.\n",
        "\n",
        "Factful, Humble, Helpful, Clear Answer in Korean:\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=PROMPT)\n",
        "\n",
        "# question=\"Based on this news, please summarize the commonalities of the companies in Korean.\"\n",
        "\n",
        "question=\"내가 준 context를 바탕으로 노타의 이력서에 넣을 문항에 답변을 해줘. 문항은 당신이 왜 이 회사에 지원했나? 이야. 답변에는 내가 이 회사의 문화와 얼마나 잘 맞는지에 대해 500자 이내로 작성해줘. 일단 나는 졸업프로젝트로 ML 모델 구축 경험이 있고 ownership을 가진 사람이니깐 그에 맞춘 이력서를 작성해줘.\"\n",
        "\n",
        "print(chain.run(context=context,\n",
        "          question=question))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpishs85Im2p",
        "outputId": "e4a7f2b0-1b9c-4821-ec80-cea916dd25cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저는 노타에 지원한 이유는 회사의 문화와 제가 잘 맞기 때문입니다. 노타는 AI 보편화를 추구하는 기업으로, 다양한 산업과 애플리케이션에 걸쳐 AI 사용을 보편화하여 모든 사람에게 어디에서나 AI를 활용할 수 있는 것을 목표로 합니다. 이러한 목표에 공감하고, 제가 졸업 프로젝트로 ML 모델 구축 경험이 있기 때문에 노타에서 제 기술과 역량을 발휘할 수 있다고 생각합니다. 또한, 노타의 문화는 고객 중심적인 결정을 내리고, 대담한 목표를 제시하며, 주도적으로 행동하는 것을 중요시하는 것 같습니다. 이러한 문화와 제가 가진 ownership을 가진 사람이라는 자질이 잘 맞아 노타에서 성장하고 싶다고 생각합니다. 노타의 AI 최적화 기술과 다양한 파트너십을 통해 해외 AI 시장 진출에도 박차를 가하고 있는 것을 보면, 노타는 성장 가능성이 큰 기업이라고 생각합니다. 따라서, 노타에서 제 기술과 역량을 발휘하며 함께 성장하고 싶습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 벡터DB 써볼거임"
      ],
      "metadata": {
        "id": "NLdCAvUMOnLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader\n"
      ],
      "metadata": {
        "id": "8dHuPyirIpAQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anKTt67zMNWH",
        "outputId": "fe0998a8-70b0-4dff-daf6-c218251179b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.10-py3-none-any.whl (422 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.4/422.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.12)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.5.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.4)\n",
            "Collecting huggingface_hub<0.17,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.1.3)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=a05b66561226c4b26f524dcf884e734266fd93dbcf921cb0058bb523d790d57c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, websockets, uvloop, python-dotenv, pulsar-client, overrides, humanfriendly, httptools, h11, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, starlette, posthog, huggingface_hub, coloredlogs, tokenizers, onnxruntime, fastapi, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.0.1 chroma-hnswlib-0.7.3 chromadb-0.4.10 coloredlogs-15.0.1 fastapi-0.99.1 h11-0.14.0 httptools-0.6.0 huggingface_hub-0.16.4 humanfriendly-10.0 monotonic-1.6 onnxruntime-1.15.1 overrides-7.4.0 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 python-dotenv-1.0.0 starlette-0.27.0 tokenizers-0.14.0 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.20.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "optykNySMbSn",
        "outputId": "169e4c30-3295-4eae-b229-68114a694138"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context= \"    AI 보편화를 추구하는 기업, 노타입니다. 노타는 다양한 산업과 애플리케이션 전반에 걸쳐 AI 사용을 보편화하여 모든 사람에게 어디에서나 AI를 활용할 수 있는 것을 목표로 합니다. 노타의 핵심 제품은 인공지능 원천기술인 딥러닝 모델 경량화 기술을 기반으로 AI 모델 개발 프로세스를 자동화 하는 AI 최적화 플랫폼, **넷츠프레소(NetsPresso)**입니다. 더불어 노타의 AI 최적화 기술은 지능형 교통 시스템 및 저전력 운전자 모니터링 시스템을 포함한 다양한 AI 솔루션 또한 제안합니다. 국내 스타트업으로는 최초로 삼성과 LG의 투자 유치 기록을 보유하고 있으며, 네이버 D2SF가 최초로 투자한 스타트업입니다. 노타는 세계 시장을 선도하는 NVIDIA, Intel, ARM 등과 같은 기업들과 강력한 파트너십을 구축하여 해외 AI 시장 진출에 박차를 가하고 있습니다. \\\n",
        "노타크루가 업무에 몰두할 수 있는 최적의 환경을 만들고자 합니다. 자율성에서 나오는 시너지와 효율을 위해 재택근무와 자율출퇴근제를 시행 중입니다. 또한 열일하는 노타크루를 위한 아낌 없는 지원도 준비되어 있으니, 노타와 함께 성장할 기회를 놓치지 마세요!\\\n",
        "\t•\t재택근무제 \\\n",
        "\t•\t자율출퇴근제 \\\n",
        "\t•\t간식 & 야근 식사 \\\n",
        "\t•\t야간 택시비 \\\n",
        "\t•\t팀 회식비 & 티타임 \\\n",
        "\t•\t모션 데스크 \\\n",
        "\t•\t업무에 최적화된 사무 공간\\\n",
        "노타크루가 오너십을 가진다면 회사의 발전이 본인의 발전이라고 느낄 수 있고, 성장에 더욱 보람을 느낄 수 있어요. 우리 회사는 노타크루가 노타를 내 회사라고 느끼고 더 아끼길 바라기 때문에 그만큼 회사가 먼저 노력해야 한다고 믿어요.\\\n",
        "Customer-Centric\\\n",
        "우리는 AI 보편화를 위해 더 많은 사람이 우리의 기술력을 느낄 수 있도록 고객 중심적인 결정을 내려야 해요.\\\n",
        "우리의 고객이 누구인지 인지하고 의사결정을 했는지, 고객이 가장 원하는 부분을 최대한 충족시키고자 했는지, 고객 중심적인 관점에서 바라보고 업무를 진행해요.\\\n",
        "Think Big\\\n",
        "세상을 혁신하고자 하는 우리는 보다 대담한 목표를 제시할 필요가 있어요. 그런 우리가 눈앞에 있는 일에만 매몰되어 있을 틈은 없겠죠. 더욱 높이, 더욱 멀리 내다보며 장기적인 성공을 향해 나아가는 것이 Think Big 하는 우리의 자세입니다.\\\n",
        "Be Proactive\\\n",
        "누군가가 나서기 전에 내가 앞서서, 누군가가 시키기 전에 내가 먼저 행동하는 것이 Proactive한 사람의 기본자세입니다. 작은 움직임이라고 생각이 들어도 내가 주도적으로 행동한다면, 그 움직임이 차곡차곡 쌓여 큰 변화를 이루어낼 수 있어요.\\\n",
        "이것은 곧 프로(Pro)다운 행동(Active)이기도 하지요!\\\n",
        "Disagree & Commit\\\n",
        "생산적인 논쟁을 위해서 우리는 더욱 적극적으로 파악하고 비판해야 해요. 다름을 인정하고 건설적인 피드백을 나누는 과정에서 더 나은 방향을 찾게 될 수 있고 어쩌면 생각지도 못한 새로운 결과가 도출될 수도 있어요. 또한, 같은 목표를 가지고 결정된 내용이기 때문에 결론에 대한 믿음도 수용의 일부라고 생각해야해요.\\\n",
        " \""
      ],
      "metadata": {
        "id": "5vFprUc2KoNf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트 토큰화"
      ],
      "metadata": {
        "id": "zgPWS982OsYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "doc = text_splitter.create_documents(context)"
      ],
      "metadata": {
        "id": "uWIMer5fJP-l"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "임베딩 스토어로 chroma 사용.\n",
        "chroma가 데이터베이스 파일을 저장할 디렉토리 지정"
      ],
      "metadata": {
        "id": "itXhYnBUOz1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = \"content/chroma/romeo\""
      ],
      "metadata": {
        "id": "wxIxp-exKi2k"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "2-PJ_v0TL9Ft"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "텍스트를 벡터 임베딩으로 변환하여 벡터 데이터베이스에 저장"
      ],
      "metadata": {
        "id": "Jn3et24lO98L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vectordb = Chroma.from_documents(doc, embeddings, persist_directory=persist_directory)\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "nL8ZIM-OLjng"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "체인 구성하기"
      ],
      "metadata": {
        "id": "AzjbtargPDoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.conversational_retrieval.base import ChatVectorDBChain\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "chain = ChatVectorDBChain.from_llm(llm, vectordb, return_source_documents=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INJMMZpbL3qb",
        "outputId": "8cb5a5d4-f131-43f1-d0ff-ddcdd8222b1d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/conversational_retrieval/base.py:378: UserWarning: `ChatVectorDBChain` is deprecated - please use `from langchain.chains import ConversationalRetrievalChain`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "질문하고 답변받기"
      ],
      "metadata": {
        "id": "gIfzupoUPFdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"내가 준 context를 바탕으로 노타의 이력서에 넣을 문항에 답변을 해줘. 문항은 당신이 왜 이 회사에 지원했나? 이야. 답변에는 내가 이 회사의 문화와 얼마나 잘 맞는지에 대해 500자 이내로 작성해줘. 일단 나는 졸업프로젝트로 ML 모델 구축 경험이 있고 ownership을 가진 사람이니깐 그에 맞춘 이력서를 작성해줘.\"\n",
        "result = chain({\"question\": query, \"chat_history\": []})"
      ],
      "metadata": {
        "id": "aaC9r74UM0Gb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "zrVPxtrZNARL",
        "outputId": "d366698b-3011-4960-9b06-1b64237b7a60"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'저는 이 회사에 지원한 이유는 여러 가지 이유가 있습니다. 첫째로, 저는 졸업 프로젝트를 통해 머신 러닝 모델을 구축하는 경험이 있습니다. 이 회사는 머신 러닝과 인공 지능 분야에서 선도적인 기술을 보유하고 있으며, 제가 가진 기술과 경험을 발전시킬 수 있는 좋은 기회라고 생각합니다.\\n\\n둘째로, 저는 ownership을 가진 사람입니다. 이 회사는 자율성과 책임감을 강조하는 문화를 가지고 있으며, 제가 가진 ownership 정신과 잘 맞는다고 생각합니다. 저는 주어진 업무에 대해 책임을 지고 최선을 다하는 것을 중요하게 생각하며, 이 회사에서는 그러한 가치를 공유하는 사람들과 함께 일할 수 있다는 점이 매우 매력적입니다.\\n\\n또한, 이 회사의 문화와 저의 가치관이 잘 맞는다고 생각합니다. 이 회사는 협업과 소통을 중요시하며, 다양한 배경과 경험을 가진 사람들이 함께 일하는 환경을 조성하고 있습니다. 저는 다양한 사람들과 함께 일하고 아이디어를 공유하는 것을 즐기며, 이 회사에서는 그러한 문화가 활발히 이루어진다고 들었습니다.\\n\\n이러한 이유들로 인해, 저는 이 회사에 지원하게 되었습니다. 제가 가진 기술과 경험을 발전시킬 수 있는 기회를 갖고, ownership 정신을 발휘하며 협업과 소통을 통해 함께 성장할 수 있는 이 회사에서 일하고 싶습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[\"source_documents\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N98CZb8NGv2",
        "outputId": "27d62a08-f668-4c61-f07f-87abfde80c76"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='네', metadata={}),\n",
              " Document(page_content='네', metadata={}),\n",
              " Document(page_content='직', metadata={}),\n",
              " Document(page_content='직', metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영어로 해봤는데 개이상하게 됨"
      ],
      "metadata": {
        "id": "FWfT63rcPIN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please answer the questions for Nota's resume based on the context I gave you. The question is, why did you apply for this company? Hey. Please write in less than 500 characters about how well I fit into this company's culture. First of all, I have experience building an ML model as a graduation project and have an understanding, so please write a resume accordingly\"\n",
        "result = chain({\"question\": query, \"chat_history\": []})\n",
        "result['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "O5-VN8slNLXn",
        "outputId": "28102bc5-92b4-463d-8429-7ad24d6dd747"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"As an AI language model, I don't have access to the specific context or information about Nota's resume. However, I can provide you with a general response. When answering why you applied for a company, it's important to highlight your interest in the company's mission, values, and culture. You can mention how your skills and experience align with the company's goals and how you believe you can contribute to their success. Additionally, you can emphasize your experience in building ML models and your understanding of the field, showcasing your ability to contribute to the company's technical requirements.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mDsRqS2ZNmvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}